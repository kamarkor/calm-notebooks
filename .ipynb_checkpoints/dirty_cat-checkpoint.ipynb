{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6935553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dirty_cat import datasets\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "employee_salaries = datasets.fetch_employee_salaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28e88682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = employee_salaries.X[['employee_position_title', 'year_first_hired', 'assignment_category']]\n",
    "y = employee_salaries.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a83bdaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_position_title</th>\n",
       "      <th>year_first_hired</th>\n",
       "      <th>assignment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Office Services Coordinator</td>\n",
       "      <td>1986</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Master Police Officer</td>\n",
       "      <td>1988</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Worker IV</td>\n",
       "      <td>1989</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resident Supervisor II</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planning Specialist III</td>\n",
       "      <td>2007</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_position_title  year_first_hired assignment_category\n",
       "0  Office Services Coordinator              1986    Fulltime-Regular\n",
       "1        Master Police Officer              1988    Fulltime-Regular\n",
       "2             Social Worker IV              1989    Fulltime-Regular\n",
       "3       Resident Supervisor II              2014    Fulltime-Regular\n",
       "4      Planning Specialist III              2007    Fulltime-Regular"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34c9a265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fulltime-Regular    8394\n",
       "Parttime-Regular     834\n",
       "Name: assignment_category, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.assignment_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35553a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police Officer III                                883\n",
       "Firefighter/Rescuer III                           694\n",
       "Bus Operator                                      638\n",
       "Manager III                                       243\n",
       "Correctional Officer III (Corporal)               228\n",
       "                                                 ... \n",
       "Director Office of Intergovernmental Relations      1\n",
       "Food Service Manager                                1\n",
       "Executive Administrative Aide to CAO                1\n",
       "Director Department of Technology Services          1\n",
       "Director Department of Public Libraries             1\n",
       "Name: employee_position_title, Length: 385, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.employee_position_title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca6b1d",
   "metadata": {},
   "source": [
    "Before building machine learning models, it is important to deal with categorical variables. Some variables are simple, for instance the \"assignment_category\" variable which has only 2 modalities (full-time or part-time). On the other hand, the \"employee_position_title\" variable contains a large number of modalities which is problematic and therefore a one-hot encoding would not be really suitable. In this notebook, we will explore the **dirty cat** library, which contains methods suitable for this kind of \"dirty\" categorical variables.\n",
    "\n",
    "Some titles appear much more than others while others only appear once and this could be a problem because it is possible that we find a value in the train and not in the test or vice versa. For example, we notice that some titles contain the word \"director\", it could be interesting to group them together in order to have unique information rather than having several titles of directors separately. We are therefore going to separate the text into several words and then for each word, we are going to construct a feature using Scikit-Learn's CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b16a82b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9228, 321)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer().fit(X['employee_position_title'])\n",
    "cv.transform(X['employee_position_title']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43daa2e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'office': 194,\n",
       " 'services': 267,\n",
       " 'coordinator': 67,\n",
       " 'master': 182,\n",
       " 'police': 211,\n",
       " 'officer': 195,\n",
       " 'social': 273,\n",
       " 'worker': 318,\n",
       " 'iv': 159,\n",
       " 'resident': 250}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 items\n",
    "dict(itertools.islice(cv.vocabulary_.items(),10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b910504",
   "metadata": {},
   "source": [
    "But what is there are some typos in the titles ? What if one wrote \"afficer\" instead of \"officer\" for instance ? This can be handled by adding some parameters to the CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1013b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9228, 3702)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer='char',\n",
    "                     ngram_range=(2,4)\n",
    "                    ).fit(X['employee_position_title'])\n",
    "cv.transform(X['employee_position_title']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a101c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 2404,\n",
       " 'ff': 1357,\n",
       " 'fi': 1369,\n",
       " 'ic': 1614,\n",
       " 'ce': 673,\n",
       " 'e ': 938,\n",
       " ' s': 230,\n",
       " 'se': 3102,\n",
       " 'er': 1168,\n",
       " 'rv': 3026}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(itertools.islice(cv.vocabulary_.items(),10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7157f38",
   "metadata": {},
   "source": [
    "We get a sparse matrix where overlaps are a sign of similarity. The **dirty_cat** library has a feature generation trick called the **SimilarityEncoder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4473cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['employee_position_title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d38e8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9228, 200)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dirty_cat\n",
    "\n",
    "mod = dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=200)\n",
    "mod.fit_transform(X[['employee_position_title']]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab74d01",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "155980ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklego.preprocessing import ColumnSelector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "method = {\n",
    "    'sim_enc100': dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=100),\n",
    "    'sim_enc300': dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=300),\n",
    "    'sim_enc_all': dirty_cat.SimilarityEncoder(),\n",
    "    'one-hot': OneHotEncoder(handle_unknown='ignore')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for k, encoder in method.items():\n",
    "    pipe = Pipeline([\n",
    "        ('split', FeatureUnion([\n",
    "            ('cat', Pipeline([\n",
    "                ('grab', ColumnSelector(['employee_position_title'])),\n",
    "                ('handle', encoder)\n",
    "            ])),\n",
    "            ('one-hot', Pipeline([\n",
    "                ('grab', ColumnSelector('assignment_category')),\n",
    "                ('handle', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ])),\n",
    "            ('floats', Pipeline([\n",
    "                ('grab', ColumnSelector('year_first_hired')),\n",
    "                ('scale', StandardScaler())\n",
    "            ])),\n",
    "        ])),\n",
    "        ('mod', Ridge())\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipe, cv=10, param_grid={}, scoring=['r2', 'neg_mean_absolute_error'], refit='r2', n_jobs=-1)\n",
    "    res_df = pd.DataFrame(grid.fit(X, y).cv_results_)\n",
    "    res_df['key'] = k\n",
    "    results.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b865c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean_test_neg_mean_absolute_error</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6319.457698</td>\n",
       "      <td>0.901871</td>\n",
       "      <td>sim_enc_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-6576.122396</td>\n",
       "      <td>0.875093</td>\n",
       "      <td>sim_enc300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-6393.584175</td>\n",
       "      <td>0.861620</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-7780.017666</td>\n",
       "      <td>0.789158</td>\n",
       "      <td>sim_enc100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  mean_test_neg_mean_absolute_error  mean_test_r2          key\n",
       "0      0                       -6319.457698      0.901871  sim_enc_all\n",
       "1      0                       -6576.122396      0.875093   sim_enc300\n",
       "2      0                       -6393.584175      0.861620      one-hot\n",
       "3      0                       -7780.017666      0.789158   sim_enc100"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.concat(results)[['mean_test_neg_mean_absolute_error','mean_test_r2','key']]\n",
    "df_results.sort_values('mean_test_r2',ascending=False).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
